{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse.linalg import svds\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy.linalg import norm\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from scipy.sparse import coo_matrix\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import base\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/Users/saranggrover/Desktop/yelp-dataset/train.csv\")\n",
    "val_df = pd.read_csv(\"/Users/saranggrover/Desktop/yelp-dataset/validation.csv\")\n",
    "test_df = pd.read_csv(\"/Users/saranggrover/Desktop/yelp-dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64658,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of users\n",
    "train_df['user_id'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64658,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['user_id'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64658,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['user_id'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49160,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of businesses\n",
    "train_df['business_id'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>attributes</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>categories</th>\n",
       "      <th>avg_business_stars</th>\n",
       "      <th>avg_user_star</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0HWPTEnVT7L5BCKj33erLQ</td>\n",
       "      <td>iGtInQDTZ89mKnkhFWdlfA</td>\n",
       "      <td>HMSDOjt_KCyknzjQ9aI5Jw</td>\n",
       "      <td>I would like to start with the classic line \"I...</td>\n",
       "      <td>2018-11-04 23:44:27</td>\n",
       "      <td>{'OutdoorSeating': 'True', 'RestaurantsGoodFor...</td>\n",
       "      <td>Tomo Noodles and Dumplings</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Noodles, Restaurants, Japanese, Ramen</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Y6xCQlzc9YTXD3IKMGN-oQ</td>\n",
       "      <td>O3cItff0mKAfXtl5VmbW2w</td>\n",
       "      <td>yXiDD18UV49-7UhA6dWjAw</td>\n",
       "      <td>We come here for once at least once a month. I...</td>\n",
       "      <td>2018-09-07 20:41:42</td>\n",
       "      <td>{'GoodForMeal': \"{'dessert': False, 'latenight...</td>\n",
       "      <td>Giacomo's Pizzeria and Italian Restaurant</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>Sandwiches, Pizza, Italian, Restaurants, Event...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9j_uLXkEgpN52Lz5VJ8sMQ</td>\n",
       "      <td>U5YQX_vMl_xQy8EQDqlNQQ</td>\n",
       "      <td>VSNUFYBQ_wOFmRXZ8SeQ4w</td>\n",
       "      <td>First meal in Pittsburgh was courtesy of S&amp;D! ...</td>\n",
       "      <td>2015-09-30 02:07:55</td>\n",
       "      <td>{'Alcohol': \"u'none'\", 'DogsAllowed': 'False',...</td>\n",
       "      <td>S&amp;D Polish Deli</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>Polish, Ethnic Food, Specialty Food, Food, Res...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.48</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>xilO0UqpI_EYJg0nzTBqzw</td>\n",
       "      <td>JrgMipJRhagq42ROTzC_CQ</td>\n",
       "      <td>lVVJMvqu4LXL5rBqjO6eqg</td>\n",
       "      <td>The Pork bone soup is delicious! The broth loo...</td>\n",
       "      <td>2015-05-30 07:40:17</td>\n",
       "      <td>{'HasTV': 'False', 'WiFi': \"u'no'\", 'BusinessP...</td>\n",
       "      <td>Tofu Village - House of Soon Tofu</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Restaurants, Korean</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.53</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>P5LDWTH6cxQK-_IWtvyOWw</td>\n",
       "      <td>8lofUN7rFkwT2bw4b5SM4g</td>\n",
       "      <td>EEIz44ewHhOKmfTloAK13g</td>\n",
       "      <td>Words cannot express how delectably divine a d...</td>\n",
       "      <td>2017-11-19 16:47:26</td>\n",
       "      <td>{'RestaurantsPriceRange2': '4', 'RestaurantsTa...</td>\n",
       "      <td>Alo Restaurant</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Bars, Nightlife, Restaurants, French</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.97</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  0HWPTEnVT7L5BCKj33erLQ  iGtInQDTZ89mKnkhFWdlfA  HMSDOjt_KCyknzjQ9aI5Jw   \n",
       "1  Y6xCQlzc9YTXD3IKMGN-oQ  O3cItff0mKAfXtl5VmbW2w  yXiDD18UV49-7UhA6dWjAw   \n",
       "2  9j_uLXkEgpN52Lz5VJ8sMQ  U5YQX_vMl_xQy8EQDqlNQQ  VSNUFYBQ_wOFmRXZ8SeQ4w   \n",
       "3  xilO0UqpI_EYJg0nzTBqzw  JrgMipJRhagq42ROTzC_CQ  lVVJMvqu4LXL5rBqjO6eqg   \n",
       "4  P5LDWTH6cxQK-_IWtvyOWw  8lofUN7rFkwT2bw4b5SM4g  EEIz44ewHhOKmfTloAK13g   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  I would like to start with the classic line \"I...  2018-11-04 23:44:27   \n",
       "1  We come here for once at least once a month. I...  2018-09-07 20:41:42   \n",
       "2  First meal in Pittsburgh was courtesy of S&D! ...  2015-09-30 02:07:55   \n",
       "3  The Pork bone soup is delicious! The broth loo...  2015-05-30 07:40:17   \n",
       "4  Words cannot express how delectably divine a d...  2017-11-19 16:47:26   \n",
       "\n",
       "                                          attributes  \\\n",
       "0  {'OutdoorSeating': 'True', 'RestaurantsGoodFor...   \n",
       "1  {'GoodForMeal': \"{'dessert': False, 'latenight...   \n",
       "2  {'Alcohol': \"u'none'\", 'DogsAllowed': 'False',...   \n",
       "3  {'HasTV': 'False', 'WiFi': \"u'no'\", 'BusinessP...   \n",
       "4  {'RestaurantsPriceRange2': '4', 'RestaurantsTa...   \n",
       "\n",
       "                                        name        city  \\\n",
       "0                 Tomo Noodles and Dumplings   Las Vegas   \n",
       "1  Giacomo's Pizzeria and Italian Restaurant   Charlotte   \n",
       "2                            S&D Polish Deli  Pittsburgh   \n",
       "3          Tofu Village - House of Soon Tofu     Toronto   \n",
       "4                             Alo Restaurant     Toronto   \n",
       "\n",
       "                                          categories  avg_business_stars  \\\n",
       "0              Noodles, Restaurants, Japanese, Ramen                 4.0   \n",
       "1  Sandwiches, Pizza, Italian, Restaurants, Event...                 4.0   \n",
       "2  Polish, Ethnic Food, Specialty Food, Food, Res...                 4.5   \n",
       "3                                Restaurants, Korean                 4.5   \n",
       "4               Bars, Nightlife, Restaurants, French                 4.5   \n",
       "\n",
       "   avg_user_star  stars  \n",
       "0           3.04    1.0  \n",
       "1           4.15    4.0  \n",
       "2           3.48    4.0  \n",
       "3           2.53    4.0  \n",
       "4           3.97    5.0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "- This part converts certain columns to a workable format (string to dict, string to list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_str_to_dict(row):\n",
    "    return literal_eval(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_str_to_list(row):\n",
    "    l = row.strip().split(\",\")\n",
    "    for s in l:\n",
    "        s = s.strip()\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['attributes'] = train_df['attributes'].apply(convert_str_to_dict)\n",
    "val_df['attributes'] = val_df['attributes'].apply(convert_str_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['categories'] = train_df['categories'].apply(convert_str_to_list)\n",
    "val_df['categories'] = val_df['categories'].apply(convert_str_to_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 4., 5., 3., 2.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['stars'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ratings(row):\n",
    "    x = int(row)\n",
    "    if x in [1, 2, 3]:\n",
    "        new_rating = 0\n",
    "    else:\n",
    "        new_rating = 1\n",
    "    return new_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['likes'] = train_df['stars'].apply(convert_ratings)\n",
    "val_df['likes'] = val_df['stars'].apply(convert_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_df['likes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = val_df['likes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(columns=['date', 'review_id', 'text', 'stars'], inplace=True)\n",
    "val_df.drop(columns=['date', 'review_id', 'text', 'stars'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['business_id', 'user_id', 'attributes', 'name', 'city', 'categories',\n",
      "       'avg_business_stars', 'avg_user_star', 'likes'],\n",
      "      dtype='object')\n",
      "Index(['business_id', 'user_id', 'attributes', 'name', 'city', 'categories',\n",
      "       'avg_business_stars', 'avg_user_star', 'likes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns)\n",
    "print(val_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Value_To_Dict(val):\n",
    "    return {val:1}\n",
    "\n",
    "def List_To_Dict(the_list):\n",
    "    return {category:1 for category in the_list}\n",
    "    \n",
    "def Flatten_Dict(d, prekey = ''):\n",
    "    flat_dict = {}\n",
    "    for key in d:\n",
    "        if isinstance(d[key], bool) and d[key]:\n",
    "            flat_dict.update({prekey+'_'+key:1})\n",
    "        elif isinstance(d[key], str):\n",
    "            flat_dict.update({prekey+'_'+key+'_'+d[key]:1})\n",
    "        elif isinstance(d[key], dict):\n",
    "            flat_dict.update(Flatten_Dict(d[key], prekey=prekey+'_'+key))\n",
    "    return flat_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class One_Hot_Encoder(base.BaseEstimator, base.TransformerMixin):\n",
    "    def __init__(self, colnames, value_type = 'value', sparse = True):\n",
    "        if value_type == 'value':\n",
    "            self.apply_function_ = Value_To_Dict\n",
    "        elif value_type == 'list':\n",
    "            self.apply_function_ = List_To_Dict\n",
    "        elif value_type == 'dict':\n",
    "            self.apply_function_ = Flatten_Dict\n",
    "        self.colnames_ = colnames\n",
    "        self.dv_ = DictVectorizer(sparse = sparse)\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        self.dv_.fit(X[self.colnames_].apply(self.apply_function_))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.dv_.transform(X[self.colnames_].apply(self.apply_function_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Column_Selector(base.BaseEstimator, base.TransformerMixin):\n",
    "    def __init__(self, colnames):\n",
    "        self.colnames_ = colnames\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return pd.DataFrame(X[self.colnames_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "- Categories\n",
    "- Attributes\n",
    "- City\n",
    "- Average business rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features for each restaurant\n",
    "\n",
    "encoding_category = One_Hot_Encoder('categories', 'list', sparse=False)\n",
    "encoding_attribute = One_Hot_Encoder('attributes', 'dict', sparse=False)\n",
    "encoding_city= One_Hot_Encoder('city', 'value', sparse=False)\n",
    "business_rating = Column_Selector(['avg_business_stars'])\n",
    "\n",
    "encoding_union = FeatureUnion([ ('cat', encoding_category), \n",
    "                               ('attr', encoding_attribute),\n",
    "                               ('city', encoding_city), \n",
    "                               ('avg_business_rating', business_rating),\n",
    "                              ])\n",
    "\n",
    "\n",
    "train_features = encoding_union.fit_transform(train_df)\n",
    "val_features = encoding_union.transform(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1078332, 2612)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269584, 2612)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create User Profiles using ML classification models\n",
    "\n",
    "- Maybe we don't scale the data to weight it more heavily on the average business ratings based on popularity?\n",
    "- Other wise:\n",
    "    - Scale the numeric features and one-hot encode the categorical ones.\n",
    "- Also, some users like all the restaurants or none of the restaurants which causes a problem with sklearn's classifiers, so we will default to most popular restaurant in a given area that a user has not been to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features[:, -1] = sc.fit_transform(train_features[:, -1].reshape(-1, 1))[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_features[:, -1] = sc.transform(val_features[:, -1].reshape(-1, 1))[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(train_feats, train_labels):\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(train_feats, train_labels)\n",
    "    return clf\n",
    "\n",
    "def naive_bayes(train_feats, train_labels):\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(train_feats, train_labels)\n",
    "    return clf\n",
    "\n",
    "def logistic_regression(train_feats, train_labels):\n",
    "    clf = LogisticRegression(solver='liblinear')\n",
    "    clf.fit(train_feats, train_labels)\n",
    "    return clf\n",
    "\n",
    "def gaussian_process(train_feats, train_labels):\n",
    "    clf = GaussianProcessClassifier()\n",
    "    clf.fit(train_feats, train_labels)\n",
    "    return clf\n",
    "\n",
    "def random_forest(train_feats, train_labels):\n",
    "    clf = RandomForestClassifier(n_estimators=10)\n",
    "    clf.fit(train_feats, train_labels)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_algo(clf, test_feats, test_labels):\n",
    "    predictions = clf.predict(test_feats)\n",
    "#     print(predictions)\n",
    "    f1 = f1_score(test_labels, predictions, average='binary')\n",
    "    acc = balanced_accuracy_score(test_labels, predictions)\n",
    "    return f1, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = train_df['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64658,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validating models for each user\n",
    "\n",
    "- Train each model on the user review ratings in train set, validate on validation set, and select best algorithm based on the algorithm that performed the best in terms of accuracy and save that model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f241a4af5a4dc19ee7a31c95b37483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=64658), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_rf_acc = 0.\n",
    "total_rf_f1 = 0.\n",
    "total_lr_acc = 0.\n",
    "total_lr_f1 = 0.\n",
    "total_gb_acc = 0.\n",
    "total_gb_f1 = 0.\n",
    "final_clf_list = []\n",
    "bad_count = 0.\n",
    "val_bad = 0.\n",
    "with open(\"/Users/saranggrover/Desktop/yelp-dataset/user_profile_standard_scaled.csv\", \"w\") as output:\n",
    "    writer = csv.writer(output, delimiter=',')\n",
    "    writer.writerow(('user_id', 'Random Forest', 'Logistic Regression', 'Naive Bayes', 'MAX', 'Best Model'))\n",
    "    for index, user in enumerate(tqdm(unique_users)):\n",
    "        train_inds = train_df[train_df['user_id'].values == user].index.values\n",
    "        val_inds = val_df[val_df['user_id'].values == user].index.values\n",
    "        \n",
    "        train_labels = train_df['likes'].values[train_inds]\n",
    "        val_labels = val_df['likes'].values[val_inds]\n",
    "        \n",
    "        if (np.all(train_labels)) or (not np.any(train_labels)):\n",
    "            bad_count += 1\n",
    "            if (np.all(val_labels)) or (not np.any(val_labels)):\n",
    "                val_bad += 1\n",
    "            writer.writerow((user, None, None, None, None, \"most_popular\"))\n",
    "            final_clf_list.append((user, \"most_popular_{}\".format(train_labels[0])))\n",
    "            \n",
    "            continue\n",
    "        else:\n",
    "            train_feats = train_features[train_inds]\n",
    "            val_feats = val_features[val_inds]\n",
    "            rf = random_forest(train_feats, train_labels)\n",
    "            lr = logistic_regression(train_feats, train_labels)\n",
    "            gb = naive_bayes(train_feats, train_labels)\n",
    "\n",
    "            rf_f1, rf_acc = test_algo(rf, val_feats, val_labels)\n",
    "            lr_f1, lr_acc = test_algo(lr, val_feats, val_labels)\n",
    "            gb_f1, gb_acc = test_algo(gb, val_feats, val_labels)\n",
    "\n",
    "            \n",
    "        total_rf_acc += rf_f1\n",
    "        total_rf_f1 += rf_acc\n",
    "        total_lr_acc += lr_acc\n",
    "        total_lr_f1 += lr_f1\n",
    "        total_gb_acc += gb_acc\n",
    "        total_gb_f1 += gb_f1\n",
    "        max_acc = max(rf_acc, lr_acc, gb_acc)\n",
    "        final_clf = None\n",
    "        if rf_acc == max_acc:\n",
    "            final_clf = rf\n",
    "        elif lr_acc == max_acc:\n",
    "            final_clf = lr\n",
    "        elif gb_acc == max_acc:\n",
    "            final_clf = gb\n",
    "        else:\n",
    "            raise Exception(\"could not find final classifier....\")\n",
    "      \n",
    "        writer.writerow((user, rf_acc, lr_acc, gb_acc, max(rf_acc, lr_acc, gb_acc), type(final_clf).__name__))\n",
    "        # Append user_id and best model\n",
    "        final_clf_list.append((user, type(final_clf).__name__))\n",
    "    \n",
    "        \n",
    "total_rf_acc /= (len(unique_users) - bad_count)\n",
    "total_rf_f1 /= (len(unique_users) - bad_count)\n",
    "total_lr_f1 /= (len(unique_users) - bad_count)\n",
    "total_lr_acc /= (len(unique_users) - bad_count)\n",
    "total_gb_f1 /= (len(unique_users) - bad_count)\n",
    "total_gb_acc /= (len(unique_users) - bad_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4236.0\n"
     ]
    }
   ],
   "source": [
    "print(val_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: RF: 57.92%, LR: 63.71%, GB: 60.83%\n",
      "Total f1 score: RF: 59.91%, LR: 63.67%, GB: 60.81%\n"
     ]
    }
   ],
   "source": [
    "print(\"Total accuracy: RF: {:.2%}, LR: {:.2%}, GB: {:.2%}\".format(float(total_rf_acc), float(total_lr_acc), float(total_gb_acc)))\n",
    "print(\"Total f1 score: RF: {:.2%}, LR: {:.2%}, GB: {:.2%}\".format(float(total_rf_f1), float(total_lr_f1), float(total_gb_f1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/saranggrover/Desktop/yelp-dataset/user_model_standard_scaled.csv','w') as out:\n",
    "    csv_out=csv.writer(out)\n",
    "    csv_out.writerow(['user_id', 'best_model'])\n",
    "    csv_out.writerows(final_clf_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments\n",
    "\n",
    "- No scaling:\n",
    "    - Total accuracy: RF: 57.94%, **LR: 62.32%**, GB: 60.81%\n",
    "    - Total f1 score: RF: 59.92%, **LR: 63.34%**, GB: 60.79%\n",
    "- Scaling:\n",
    "    - StandardScaler\n",
    "        - Total accuracy: RF: 57.92%, **LR: 63.71%**, GB: 60.83%\n",
    "        - Total f1 score: RF: 59.91%, **LR: 63.67%**, GB: 60.81%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation on Test Set\n",
    "\n",
    "- Using the chosen models for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile_models = pd.read_csv(\"/Users/saranggrover/Desktop/yelp-dataset/user_model_standard_scaled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>best_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iGtInQDTZ89mKnkhFWdlfA</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O3cItff0mKAfXtl5VmbW2w</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U5YQX_vMl_xQy8EQDqlNQQ</td>\n",
       "      <td>GaussianNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JrgMipJRhagq42ROTzC_CQ</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8lofUN7rFkwT2bw4b5SM4g</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id              best_model\n",
       "0  iGtInQDTZ89mKnkhFWdlfA  RandomForestClassifier\n",
       "1  O3cItff0mKAfXtl5VmbW2w      LogisticRegression\n",
       "2  U5YQX_vMl_xQy8EQDqlNQQ              GaussianNB\n",
       "3  JrgMipJRhagq42ROTzC_CQ  RandomForestClassifier\n",
       "4  8lofUN7rFkwT2bw4b5SM4g  RandomForestClassifier"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_profile_models.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['attributes'] = test_df['attributes'].apply(convert_str_to_dict)\n",
    "test_df['categories'] = test_df['categories'].apply(convert_str_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(columns=['date', 'review_id', 'text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['likes'] = test_df['stars'].apply(convert_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = encoding_union.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features[:, -1] = sc.transform(test_features[:, -1].reshape(-1, 1))[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unique_users = test_df['user_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5adaa6cc534571a95a1f0f538d24e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=336980), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 148, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_test_f1 = 0.\n",
    "total_test_acc = 0.\n",
    "\n",
    "for index, user in enumerate(tqdm(test_unique_users)):\n",
    "    train_inds = train_df[train_df['user_id'].values == user].index.values\n",
    "    test_inds = test_df[test_df['user_id'].values == user].index.values\n",
    "    \n",
    "    train_labels = train_df['likes'].values[train_inds]\n",
    "    test_labels = test_df['likes'].values[test_inds]\n",
    "    \n",
    "    train_feats = train_features[train_inds]\n",
    "    test_feats = test_features[test_inds]\n",
    "    \n",
    "    active_user_model = user_profile_models[user_profile_models['user_id'].values == user]['best_model'].values[0]\n",
    "#     print(active_user_model)\n",
    "    user_clf = None\n",
    "    if active_user_model == \"LogisticRegression\":\n",
    "        user_clf = logistic_regression(train_feats, train_labels)\n",
    "    elif active_user_model == \"RandomForestClassifier\":\n",
    "        user_clf = random_forest(train_feats, train_labels)\n",
    "    else:\n",
    "        user_clf = naive_bayes(train_feats, train_labels)\n",
    "    \n",
    "    u_f1, u_acc = test_algo(user_clf, test_feats, test_labels)\n",
    "    total_test_f1 += u_f1\n",
    "    total_test_acc += u_acc\n",
    "\n",
    "total_test_f1 /= len(test_unique_users)\n",
    "total_test_acc /= len(test_unique_users)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1: 0.6599, Test Acc: 0.5923\n"
     ]
    }
   ],
   "source": [
    "print(\"Test F1: {:.4f}, Test Acc: {:.4f}\".format(total_test_f1, total_test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Results (average F1 and Accuracy per user)\n",
    "\n",
    "- Scaled with standard scaler\n",
    "    - Test F1: 0.6599, Test Acc: 0.5923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
